{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ai-ws\\anaconda3\\envs\\torch-1.8\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from operation import Conv1dNormActivation, _make_divisible, SqueezeExcitation\n",
    "\n",
    "from marnasnet import BlockConfig, ConvBlock, SeparableConvBlock, MBConvBlock, marnasnet_a, marnasnet_b, marnasnet_c, marnasnet_d, marnasnet_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 3, 112)\n",
    "# Default: None, in which case it will calculated as ``padding = (kernel_size - 1) // 2 * dilation\n",
    "layer = Conv1dNormActivation(3, 32, 3, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 112])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = layer(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf = BlockConfig(\n",
    "    conv_op=ConvBlock,\n",
    "    repeats=5, \n",
    "    kernel=5, stride=1, \n",
    "    input_channels=32, out_channels=16, \n",
    "    skip_op='identity',\n",
    "    se_ratio=0.25)\n",
    "    \n",
    "blocks_setting = [\n",
    "    cnf\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dummy input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 32, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 256])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convblock = ConvBlock(cnf)\n",
    "convblock(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 256])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepconv = SeparableConvBlock(cnf)\n",
    "sepconv(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbconv = MBConvBlock(cnf)\n",
    "mbconv(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_conf = partial(BlockConfig, se_ratio=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(1, 3, 256)\n",
    "model = marnasnet_a(init_channels=3)\n",
    "output = model(input)\n",
    "output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(1, 3, 256)\n",
    "model = marnasnet_b(init_channels=3)\n",
    "output = model(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(1, 3, 256)\n",
    "model = marnasnet_c(init_channels=3)\n",
    "output = model(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(1, 3, 256)\n",
    "model = marnasnet_d(init_channels=3)\n",
    "output = model(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(1, 3, 256)\n",
    "model = marnasnet_e(init_channels=3)\n",
    "output = model(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF Version Blcok Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import abc\n",
    "\n",
    "from enum import Enum\n",
    "from abc import *\n",
    "\n",
    "class BaseAttention(metaclass=abc.ABCMeta):\n",
    "    def __init__(self, filters, block_name):\n",
    "        self.filters = filters\n",
    "        self.block_name = block_name\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "# Squeeze-and-Excitation module\n",
    "class SqueezeAndExcite(BaseAttention):\n",
    "    \"\"\"squeeze-and-excitation module\n",
    "    \"\"\"\n",
    "    def __init__(self, filters, se_ratio=0.25, block_name=\"\"):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        filters: int\n",
    "            output filter size\n",
    "        se_ratio: float\n",
    "            se ratio, se_ratio must be greater than 0 and less than or equal to 1.\n",
    "        block_name: str\n",
    "            block name\n",
    "        \"\"\"\n",
    "        super().__init__(filters, block_name)\n",
    "        self.se_ratio = se_ratio\n",
    "\n",
    "    def __call__(self, x):\n",
    "        assert 0 < self.se_ratio <= 1, \"se_ratio must be greater than 0 and less than or equal to 1.\"\n",
    "\n",
    "        filters_se = max(1, int(self.filters * self.se_ratio))\n",
    "        se = tf.keras.layers.GlobalAveragePooling1D(name=\"{}_se_squeeze\".format(self.block_name))(x)\n",
    "        se = tf.keras.layers.Reshape((1, self.filters), name=\"{}_se_reshape\".format(self.block_name))(se)\n",
    "        se = tf.keras.layers.Conv1D(\n",
    "            filters_se,\n",
    "            1,\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            name=\"{}_se_reduce\".format(self.block_name)\n",
    "        )(se)\n",
    "        se = tf.keras.layers.Conv1D(\n",
    "            self.filters,\n",
    "            1,\n",
    "            padding=\"same\",\n",
    "            activation=\"sigmoid\",\n",
    "            kernel_initializer=\"he_normal\",\n",
    "            name=\"{}_se_expand\".format(self.block_name)\n",
    "        )(se)\n",
    "        x = tf.keras.layers.multiply([x, se], name=\"{}_se_excite\".format(self.block_name))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvOps enum\n",
    "class ConvBlock(Enum):\n",
    "    Conv = \"Conv\"\n",
    "    SeparableConv = \"SeparableConv\"\n",
    "    MBConv = \"MBConv\"\n",
    "    ExtremeInception = \"ExtremeInception\"\n",
    "\n",
    "\n",
    "# SkipOps enum\n",
    "class SkipOperation(Enum):\n",
    "    none = \"none\"\n",
    "    pool = \"pool\"\n",
    "    identity = \"identity\"\n",
    "\n",
    "\n",
    "# Base conv block\n",
    "class BaseBlock(metaclass=ABCMeta):\n",
    "    def __init__(self, repeats, kernel_size, skip_op, strides,\n",
    "                 se_ratio, block_id=1):\n",
    "        self.repeats = repeats\n",
    "        self.kernel_size = kernel_size\n",
    "        self.skip_op = skip_op\n",
    "        self.strides = strides\n",
    "        self.se_ratio = se_ratio\n",
    "        self.block_id = block_id\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, x):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegularConvBlock(BaseBlock):\n",
    "    def __init__(self, repeats: int, kernel_size: int, filters: int, skip_op: SkipOperation, strides: int,\n",
    "                 se_ratio: float, block_id=1):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        repeats: int\n",
    "            the number of convolutional layers\n",
    "        kernel_size: int\n",
    "            the dimension of the convolution window\n",
    "        filters: int\n",
    "            the number of filters\n",
    "        skip_op: Blossom.options.SkipOperation\n",
    "            skip operation\n",
    "        strides: int\n",
    "            the stride ot the convolution\n",
    "        se_ratio: float\n",
    "            between 0 and 1, fraction to squeeze the input filters\n",
    "        block_id: int\n",
    "            larger than 1, the block id\n",
    "        \"\"\"\n",
    "        super().__init__(repeats, kernel_size, skip_op, strides, se_ratio, block_id)\n",
    "        self.filters = filters\n",
    "\n",
    "    def __call__(self, x):\n",
    "        inputs = x\n",
    "\n",
    "        for i in range(self.repeats):\n",
    "            x = tf.keras.layers.Conv1D(\n",
    "                self.filters,\n",
    "                self.kernel_size,\n",
    "                self.strides,\n",
    "                padding='same',\n",
    "                activation='relu',\n",
    "                kernel_initializer='he_normal',\n",
    "                name=\"block{}{}_conv\".format(self.block_id, chr(i + 97))\n",
    "            )(x)\n",
    "\n",
    "        if 0 < self.se_ratio <= 1:\n",
    "            x = SqueezeAndExcite(self.filters, self.se_ratio, block_name=\"block{}\".format(self.block_id))(x)\n",
    "\n",
    "        if self.skip_op == SkipOperation.pool:\n",
    "            x = tf.keras.layers.MaxPooling1D(name=\"block{}_pool\".format(self.block_id), padding='same')(x)\n",
    "        elif self.skip_op == SkipOperation.identity:\n",
    "            if self.strides == 1:\n",
    "                shortcut = inputs\n",
    "                if int(inputs.shape[-1]) != int(x.shape[-1]):\n",
    "                    shortcut = tf.keras.layers.Conv1D(int(x.shape[-1]),\n",
    "                                                      1,\n",
    "                                                      strides=self.strides,\n",
    "                                                      kernel_initializer=\"he_normal\",\n",
    "                                                      padding='valid',\n",
    "                                                      name=\"block{}_shortcut\".format(self.block_id))(x)\n",
    "\n",
    "                x = tf.keras.layers.add([x, shortcut], name=\"block{}_add\".format(self.block_id))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_block = RegularConvBlock(3, 3, 32, 'identity', 1, 0.25, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 112, 3)]     0           []                               \n",
      "                                                                                                  \n",
      " block1a_conv (Conv1D)          (None, 112, 32)      320         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " block1b_conv (Conv1D)          (None, 112, 32)      3104        ['block1a_conv[0][0]']           \n",
      "                                                                                                  \n",
      " block1c_conv (Conv1D)          (None, 112, 32)      3104        ['block1b_conv[0][0]']           \n",
      "                                                                                                  \n",
      " block1_se_squeeze (GlobalAvera  (None, 32)          0           ['block1c_conv[0][0]']           \n",
      " gePooling1D)                                                                                     \n",
      "                                                                                                  \n",
      " block1_se_reshape (Reshape)    (None, 1, 32)        0           ['block1_se_squeeze[0][0]']      \n",
      "                                                                                                  \n",
      " block1_se_reduce (Conv1D)      (None, 1, 8)         264         ['block1_se_reshape[0][0]']      \n",
      "                                                                                                  \n",
      " block1_se_expand (Conv1D)      (None, 1, 32)        288         ['block1_se_reduce[0][0]']       \n",
      "                                                                                                  \n",
      " block1_se_excite (Multiply)    (None, 112, 32)      0           ['block1c_conv[0][0]',           \n",
      "                                                                  'block1_se_expand[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,080\n",
      "Trainable params: 7,080\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 입력 데이터의 크기 정의 (예: [배치 크기, 시퀀스 길이, 채널 수])\n",
    "input_shape = (None, 112, 3)  # None은 배치 크기를 나중에 지정할 수 있음을 의미합니다.\n",
    "\n",
    "# 입력 텐서 생성\n",
    "input_tensor = tf.keras.layers.Input(shape=input_shape[1:])  # 배치 크기를 제외한 나머지 차원을 지정합니다.\n",
    "\n",
    "# RegularConvBlock에 입력 텐서 전달\n",
    "output_tensor = conv_block(input_tensor)\n",
    "\n",
    "# 모델 정의 (입력과 출력 텐서를 연결)\n",
    "model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "# 모델 요약 정보 출력\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
