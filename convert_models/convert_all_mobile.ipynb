{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "from data_providers import UCIHARDataProvider, OPPDataProvider, KUHARDataProvider, UniMiBDataProvider, WISDMDataProvider"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCI-HAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* HAR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "har_model_list = [\"RTWCNN\", \"HARLSTM\", \"HARBiLSTM\", \"HARConvLSTM\", \"ResNetTSC\", \"FCNTSC\"] # TODO: \"RTCNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\RTWCNN.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\HARLSTM.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\HARBiLSTM.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\HARConvLSTM.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\ResNetTSC.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\FCNTSC.pt\n"
     ]
    }
   ],
   "source": [
    "for model in har_model_list:\n",
    "    ! python convert_har_mobile.py --dataset uci --arch $model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vision model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_model_list = [\"mobilenet_v2\", \"mobilenet_v3_small\", \"mobilenet_v3_large\", \"mnasnet0_5\", \"mnasnet0_75\", \"mnasnet1_0\", \"mnasnet1_3\", \"shufflenet_v2_x0_5\", \"shufflenet_v2_x1_0\", \"shufflenet_v2_x1_5\", \"shufflenet_v2_x2_0\", \"resnet18\", \"resnet34\", \"resnet50\", \"resnet101\", \"resnext50_32x4d\", \"resnext101_32x8d\", \"resnext101_64x4d\", \"squeezenet1_0\", \"squeezenet1_1\", \"efficientnet_b0\", \"efficientnet_b1\", \"efficientnet_b2\", \"efficientnet_b3\", \"efficientnet_b4\", \"efficientnet_b5\", \"efficientnet_b6\", \"efficientnet_b7\", \"efficientnet_v2_s\", \"efficientnet_v2_m\", \"efficientnet_v2_l\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\mobilenet_v2.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\mobilenet_v3_small.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\mobilenet_v3_large.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\mnasnet0_5.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\mnasnet0_75.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\mnasnet1_0.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\mnasnet1_3.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\shufflenet_v2_x0_5.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\shufflenet_v2_x1_0.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\shufflenet_v2_x1_5.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\shufflenet_v2_x2_0.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\resnet18.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\resnet34.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\resnet50.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\resnet101.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\resnext50_32x4d.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\resnext101_32x8d.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\resnext101_64x4d.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\squeezenet1_0.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\squeezenet1_1.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\efficientnet_b0.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\efficientnet_b1.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\efficientnet_b2.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\efficientnet_b3.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\efficientnet_b4.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\efficientnet_b5.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\efficientnet_b6.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\efficientnet_b7.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\efficientnet_v2_s.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\efficientnet_v2_m.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\efficientnet_v2_l.pt\n"
     ]
    }
   ],
   "source": [
    "for model in vision_model_list:\n",
    "    ! python convert_vision_mobile.py --dataset uci --arch $model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* harnas model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "harnas_model_list = [\"RLNAS\", \"EANAS\", \"DNAS\"]\n",
    "# harnas_model_list = [\"EANAS\", \"DNAS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment dir : mobile_pt/uci\n",
      "CPU model saved at : mobile_pt/uci\\RLNAS.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "18 48\n",
      "CPU model saved at : mobile_pt/uci\\EANAS.pt\n",
      "Experiment dir : mobile_pt/uci\n",
      "6 48\n",
      "CPU model saved at : mobile_pt/uci\\DNAS.pt\n"
     ]
    }
   ],
   "source": [
    "for model in harnas_model_list:\n",
    "    ! python convert_harnas_mobile.py --dataset uci --arch $model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* HAR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "har_model_list = [\"RTWCNN\", \"HARLSTM\", \"HARBiLSTM\", \"HARConvLSTM\", \"ResNetTSC\", \"FCNTSC\"] # TODO: \"RTCNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment dir : mobile_pt/opp\n",
      "CPU model saved at : mobile_pt/opp\\RTWCNN.pt\n",
      "Experiment dir : mobile_pt/opp\n",
      "CPU model saved at : mobile_pt/opp\\HARLSTM.pt\n",
      "Experiment dir : mobile_pt/opp\n",
      "CPU model saved at : mobile_pt/opp\\HARBiLSTM.pt\n",
      "Experiment dir : mobile_pt/opp\n",
      "CPU model saved at : mobile_pt/opp\\HARConvLSTM.pt\n",
      "Experiment dir : mobile_pt/opp\n",
      "CPU model saved at : mobile_pt/opp\\ResNetTSC.pt\n",
      "Experiment dir : mobile_pt/opp\n",
      "CPU model saved at : mobile_pt/opp\\FCNTSC.pt\n"
     ]
    }
   ],
   "source": [
    "for model in har_model_list:\n",
    "    ! python convert_har_mobile.py --dataset opp --arch $model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import rl_harnas.genotypes as genotypes\n",
    "from rl_harnas.model_generator import BNConvReLU\n",
    "\n",
    "genotype = eval(\"genotypes.{}\".format('RLNAS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(128, 1, 0),\n",
       " (32, 8, 4),\n",
       " (256, 5, 2),\n",
       " (256, 8, 4),\n",
       " (256, 8, 4),\n",
       " (256, 8, 4),\n",
       " (0, 0, 0),\n",
       " (256, 3, 1)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # index / Type / Kernel Size / Pred1 / Pred2 / N_Kernels\n",
    "# for g in genotype:\n",
    "#     k = g[2]\n",
    "#     nf = g[5]\n",
    "\n",
    "# nf / kernel_size / padding\n",
    "rlnas = [(g[5], g[2], int(g[2]/2)) for g in genotype[1:-1]]\n",
    "rlnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): BNConvReLU(\n",
       "    (conv): Conv1d(256, 256, kernel_size=(8,), stride=(1,), padding=(4,))\n",
       "    (ReLU): ReLU()\n",
       "    (BN): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (1): BNConvReLU(\n",
       "    (conv): Conv1d(256, 256, kernel_size=(8,), stride=(1,), padding=(4,))\n",
       "    (ReLU): ReLU()\n",
       "    (BN): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.ModuleList([BNConvReLU(256, 256, 8, 4),BNConvReLU(256, 256, 8, 4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1184"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32 + 128 + 256 + 256*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RLNAS(nn.Module):\n",
    "    def __init__(self, C, num_classes):\n",
    "        super(RLNAS, self).__init__()\n",
    "        self._C = C\n",
    "        self._num_classes = num_classes\n",
    "        self.get_network()\n",
    "        \n",
    "        self.lstm = nn.LSTM(1184, 128, num_layers=2, batch_first=True) # 32 + 128 + 256 + 256*3\n",
    "        self.classifier = nn.Linear(128, self._num_classes)\n",
    "\n",
    "    def get_network(self):\n",
    "        # make each layer            \n",
    "        self.layer1, self.layer2 = BNConvReLU(self._C, 128, 1, 0), BNConvReLU(self._C, 32, 8, 4)\n",
    "        self.layer3 = BNConvReLU(128, 256, 5, 2)\n",
    "        self.layer4, self.layer5, self.layer6 =  \\\n",
    "            BNConvReLU(256, 256, 8, 4), BNConvReLU(256, 256, 8, 4), BNConvReLU(256, 256, 8, 4)\n",
    "        self.layer8 = BNConvReLU(256, 256, 3, 1)   \n",
    "        # make layers\n",
    "        self._layers = nn.ModuleList([\n",
    "            self.layer1, self.layer2, \n",
    "            self.layer3, \n",
    "            self.layer4, self.layer5, self.layer6, \n",
    "            self.layer8\n",
    "        ])       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # input x -> x1, x2\n",
    "        x1, x2 = self.layer1(x), self.layer2(x)\n",
    "        # input x1 -> x3\n",
    "        x3 = self.layer3(x1)\n",
    "        # input x3 -> x4, x5, x6\n",
    "        x4, x5, x6 = self.layer4(x3), self.layer5(x3), self.layer6(x3)\n",
    "        x7, x8 = torch.cat([x1, x4], axis=1), self.layer8(x4)    \n",
    "        \n",
    "        # output\n",
    "        x = torch.cat([x2, x5, x6, x7, x8], axis=1)\n",
    "        \n",
    "        # x = x.view(x.size(0), -1, 1184)\n",
    "        # x, _ = self.lstm(x, h)\n",
    "        # x = x.view(x.size(0), -1, 128)[:, -1, :]\n",
    "\n",
    "        # x = self.classifier(x)\n",
    "\n",
    "        # return x, h\n",
    "    \n",
    "        x = x.squeeze(-1).permute([0, 2, 1])\n",
    "        lstm_out, (hn, cn) = self.lstm(x)\n",
    "        last_time_step  = lstm_out[:, -1, :]\n",
    "        logits = self.classifier(last_time_step)\n",
    "        return logits\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = RLNAS(C=6, num_classes=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Got 128 and 129 in dimension 2 (The offending index is 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-272874cd227e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\ai-ws\\anaconda3\\envs\\torch-1.8\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-ae16481edc90>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# input x3 -> x4, x5, x6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mx4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx6\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer6\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mx7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx8\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer8\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Got 128 and 129 in dimension 2 (The offending index is 1)"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 6, 128)\n",
    "net(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KUHAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "har_model_list = [\"RTWCNN\", \"HARLSTM\", \"HARBiLSTM\", \"HARConvLSTM\", \"ResNetTSC\", \"FCNTSC\"] # TODO: \"RTCNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment dir : mobile_pt/kar\n",
      "CPU model saved at : mobile_pt/kar\\RTWCNN.pt\n",
      "Experiment dir : mobile_pt/kar\n",
      "CPU model saved at : mobile_pt/kar\\HARLSTM.pt\n",
      "Experiment dir : mobile_pt/kar\n",
      "CPU model saved at : mobile_pt/kar\\HARBiLSTM.pt\n",
      "Experiment dir : mobile_pt/kar\n",
      "CPU model saved at : mobile_pt/kar\\HARConvLSTM.pt\n",
      "Experiment dir : mobile_pt/kar\n",
      "CPU model saved at : mobile_pt/kar\\ResNetTSC.pt\n",
      "Experiment dir : mobile_pt/kar\n",
      "CPU model saved at : mobile_pt/kar\\FCNTSC.pt\n"
     ]
    }
   ],
   "source": [
    "for model in har_model_list:\n",
    "    ! python convert_har_mobile.py --dataset kar --arch $model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UniMib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "har_model_list = [\"RTWCNN\", \"HARLSTM\", \"HARBiLSTM\", \"HARConvLSTM\", \"ResNetTSC\", \"FCNTSC\"] # TODO: \"RTCNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment dir : mobile_pt/uni\n",
      "CPU model saved at : mobile_pt/uni\\RTWCNN.pt\n",
      "Experiment dir : mobile_pt/uni\n",
      "CPU model saved at : mobile_pt/uni\\HARLSTM.pt\n",
      "Experiment dir : mobile_pt/uni\n",
      "CPU model saved at : mobile_pt/uni\\HARBiLSTM.pt\n",
      "Experiment dir : mobile_pt/uni\n",
      "CPU model saved at : mobile_pt/uni\\HARConvLSTM.pt\n",
      "Experiment dir : mobile_pt/uni\n",
      "CPU model saved at : mobile_pt/uni\\ResNetTSC.pt\n",
      "Experiment dir : mobile_pt/uni\n",
      "CPU model saved at : mobile_pt/uni\\FCNTSC.pt\n"
     ]
    }
   ],
   "source": [
    "for model in har_model_list:\n",
    "    ! python convert_har_mobile.py --dataset uni --arch $model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WISDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "har_model_list = [\"RTWCNN\", \"HARLSTM\", \"HARBiLSTM\", \"HARConvLSTM\", \"ResNetTSC\", \"FCNTSC\"] # TODO: \"RTCNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment dir : mobile_pt/wis\n",
      "CPU model saved at : mobile_pt/wis\\RTWCNN.pt\n",
      "Experiment dir : mobile_pt/wis\n",
      "CPU model saved at : mobile_pt/wis\\HARLSTM.pt\n",
      "Experiment dir : mobile_pt/wis\n",
      "CPU model saved at : mobile_pt/wis\\HARBiLSTM.pt\n",
      "Experiment dir : mobile_pt/wis\n",
      "CPU model saved at : mobile_pt/wis\\HARConvLSTM.pt\n",
      "Experiment dir : mobile_pt/wis\n",
      "CPU model saved at : mobile_pt/wis\\ResNetTSC.pt\n",
      "Experiment dir : mobile_pt/wis\n",
      "CPU model saved at : mobile_pt/wis\\FCNTSC.pt\n"
     ]
    }
   ],
   "source": [
    "for model in har_model_list:\n",
    "    ! python convert_har_mobile.py --dataset wis --arch $model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-harnas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
